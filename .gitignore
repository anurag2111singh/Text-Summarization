import math
import re
from collections import Counter


# Function to preprocess the text: Tokenize it into sentences and words
def preprocess_text(text):
    # Split the text into sentences using punctuation marks
    sentences = re.split(r'[.!?]', text)

    # Remove empty sentences from list after splitting
    sentences = [sentence.strip() for sentence in sentences if sentence.strip()]

    # Tokenize each sentence into words (consider only alphabets)
    words_in_sentences = []
    for sentence in sentences:
        words = re.findall(r'\b\w+\b', sentence.lower())  # Use regex to extract words and make them lowercase
        words_in_sentences.append(words)

    return sentences, words_in_sentences


# Function to compute Term Frequency (TF) for a sentence
def compute_tf(words_in_sentence):
    tf = Counter(words_in_sentence)  # Count frequency of each word in the sentence
    total_words = len(words_in_sentence)  # Total number of words in the sentence
    for word in tf:
        tf[word] = tf[word] / total_words  # Normalize by dividing by the total number of words
    return tf


# Function to compute Inverse Document Frequency (IDF) for the entire text
def compute_idf(words_in_sentences):
    idf = {}
    total_sentences = len(words_in_sentences)

    # Get the unique words across all sentences
    all_words = set(word for sentence in words_in_sentences for word in set(sentence))

    for word in all_words:
        containing_sentences = sum(1)


